{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f2dd92",
   "metadata": {},
   "source": [
    "# Call Agent Analysis Experiment\n",
    "\n",
    "This notebook runs the Call Agent Analysis Experiment using multiple LLM configurations and writes results to BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MES - 02_run_call_agent_analysis_experiment.py\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from agents.call_agent_analysis_agent import CallAgentAnalysisAgent\n",
    "from orchestration.experiment_runner import ExperimentRunner\n",
    "from orchestration.bigquery_writer import BigQueryWriter\n",
    "from core.gcp_client import (\n",
    "    get_gcs_audio_bucket_name,\n",
    "    get_gcs_audio_dataset_paths,\n",
    "    get_bq_analysis_table_id,\n",
    "    config as main_global_config\n",
    ")\n",
    "\n",
    "def run_agent_analysis_experiment():\n",
    "    print(\"--- Starting Call Agent Analysis Experiment (Multi-LLM) ---\")\n",
    "\n",
    "    runner = ExperimentRunner(agent_class=CallAgentAnalysisAgent)\n",
    "    print(\"Initialized ExperimentRunner.\")\n",
    "\n",
    "    gcs_bucket = get_gcs_audio_bucket_name()\n",
    "    dataset_paths = get_gcs_audio_dataset_paths()\n",
    "    dataset_key = 'sample_analysis_set'\n",
    "    audio_folder_path = dataset_paths.get(dataset_key)\n",
    "\n",
    "    if not audio_folder_path or 'your-gcs-bucket' in gcs_bucket or 'path/to' in audio_folder_path:\n",
    "        print(f\"ERROR: Please configure GCS bucket and '{dataset_key}' path in configs/main_config.yaml.\")\n",
    "        return\n",
    "    print(f\"Targeting GCS: gs://{gcs_bucket}/{audio_folder_path}\")\n",
    "\n",
    "    all_defined_llm_configs = list(main_global_config['gcp']['vertex_ai']['llm_configurations'].keys())\n",
    "    if not all_defined_llm_configs:\n",
    "        print(\"ERROR: No LLM configurations found in 'configs/main_config.yaml'.\")\n",
    "        return\n",
    "        \n",
    "    # llm_configs_to_test = all_defined_llm_configs # Test all\n",
    "    llm_configs_to_test = [\"gemini_1_5_flash_creative\"] # Example: test only one specific config\n",
    "    llm_configs_to_test = [name for name in llm_configs_to_test if name in all_defined_llm_configs]\n",
    "    if not llm_configs_to_test:\n",
    "        print(f\"ERROR: None of the specified llm_configs_to_test were found. Available: {all_defined_llm_configs}\")\n",
    "        return\n",
    "    print(f\"LLM configurations to be tested: {llm_configs_to_test}\")\n",
    "\n",
    "    global_llm_params_override = {\"max_output_tokens\": 600}\n",
    "    print(f\"Global LLM parameter overrides: {global_llm_params_override}\")\n",
    "    \n",
    "    # global_prompt_override = \"Analyze this agent's call for quality: {transcript}\"\n",
    "    global_prompt_override = None\n",
    "    if global_prompt_override: print(f\"Global prompt override: '{global_prompt_override}'\")\n",
    "\n",
    "    print(f\"\\nStarting experiment...\")\n",
    "    results = runner.run_experiment(\n",
    "        gcs_audio_folder_path=audio_folder_path,\n",
    "        gcs_bucket_name=gcs_bucket,\n",
    "        llm_config_names=llm_configs_to_test,\n",
    "        global_llm_parameters_override=global_llm_params_override,\n",
    "        global_prompt_override=global_prompt_override\n",
    "    )\n",
    "\n",
    "    if not results:\n",
    "        print(\"Experiment finished but produced no results.\")\n",
    "        return\n",
    "    print(f\"\\nExperiment completed. Generated {len(results)} result entries.\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nFirst 2 experiment result entries (if any):\")\n",
    "    print(results_df.head(2).to_string())\n",
    "\n",
    "    try:\n",
    "        bq_writer = BigQueryWriter()\n",
    "        analysis_table_id = get_bq_analysis_table_id()\n",
    "        print(f\"\\nAttempting to write {len(results)} results to BigQuery table: {bq_writer.dataset_id}.{analysis_table_id}\")\n",
    "        bq_writer.write_results(results, analysis_table_id)\n",
    "        print(\"Successfully wrote results to BigQuery.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing results to BigQuery: {e}\")\n",
    "        fallback_filename = \"agent_analysis_experiment_results_fallback.csv\"\n",
    "        results_df.to_csv(fallback_filename, index=False)\n",
    "        print(f\"Results saved locally to {fallback_filename} due to BigQuery error.\")\n",
    "\n",
    "    print(\"--- Call Agent Analysis Experiment Finished ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_agent_analysis_experiment()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
